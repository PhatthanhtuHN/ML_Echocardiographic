{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_echocardiographic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PhatthanhtuHN/ML_Echocardiographic/blob/main/ML_echocardiographic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rt_yvilY_rF"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision import transforms\n",
        "import torchvision\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from torchsummary import summary\n",
        "\n",
        "from collections import  namedtuple\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_Jz6Kiuc4to",
        "outputId": "fe90dc1d-37f8-44c8-bd0a-8975f724f027"
      },
      "source": [
        "drive.mount('/content/drive')\n",
        "\n",
        "# Đặt đường dẫn cho thư mục train và test từ dữ liệu Drive đã được kết nối \n",
        "train_dir = '/content/drive/MyDrive/Colab Notebooks/DATA_CHAMBER_2021/train'\n",
        "test_dir = '/content/drive/MyDrive/Colab Notebooks/DATA_CHAMBER_2021/test'"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DstH-A1zZ0AA"
      },
      "source": [
        "# Hàm get_classes() trả về ba lớp 2C, 3C, 4C tương ứng với ba loại mặt cắt của ảnh siêu âm tim\n",
        "def get_classes():\n",
        "  classes = ['2C', '3C', '4C']\n",
        "  return classes\n",
        "\n",
        "TrainTest = namedtuple('TrainTest', ['train', 'test'])\n",
        "\n",
        "# Hàm chuẩn bị dữ liệu\n",
        "def prepare_data():\n",
        "  img_size = 224\n",
        "  # Hàm transform chuẩn hóa ảnh về kích thước 224 x 224 và chuyển thành Tensor là một mảng nhiều chiều\n",
        "  transforms_train = transforms.Compose([\n",
        "    transforms.Resize((img_size, img_size)), \n",
        "    transforms.ToTensor(), \n",
        "    # transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "    #                  std=[0.229, 0.224, 0.225]) \n",
        "  ])\n",
        "  transforms_test = transforms.Compose([\n",
        "    transforms.Resize((img_size, img_size)), \n",
        "    transforms.ToTensor(), \n",
        "    # transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "    #                  std=[0.229, 0.224, 0.225]) \n",
        "  ])\n",
        "  # Chuẩn bị 2 bộ dữ liệu trainset và testset với đường dẫn như trên, gán nhãn cho ảnh theo tên thư mục và trả về bộ giá trị (tuple) TrainTest gồm hai bộ dữ liệu này\n",
        "  trainset = torchvision.datasets.ImageFolder(root=train_dir, transform=transforms_train)\n",
        "  testset = torchvision.datasets.ImageFolder(root=test_dir, transform=transforms_test)\n",
        "  print('Number of images in train:', len(trainset), '\\nNumber of images in test:', len(testset))\n",
        "  print('Index of classes:', trainset.class_to_idx)\n",
        "  print('Type:', type(trainset[0][0]), '| size: ', trainset[0][0].shape)\n",
        "  return TrainTest(train=trainset, test=testset)\n",
        "\n",
        "# Hàm đọc bộ dữ liệu, mỗi lần lấy ra 1 batch có độ dài là 32 ảnh đế xử lý song song, nối thành tensor 4 chiều là đầu vào của mạng\n",
        "def prepare_loader(datasets):\n",
        "  trainloader = DataLoader(dataset=datasets.train, batch_size=32, shuffle=True, num_workers=4)\n",
        "  testloader = DataLoader(dataset=datasets.test, batch_size=32, shuffle=False, num_workers=4)\n",
        "  print('Number of batchs in train:', len(trainloader), '\\nNumber of batchs in test:', len(testloader))\n",
        "  return TrainTest(train=trainloader, test=testloader)\n",
        "\n",
        "# Dựng mô hình mạng tích chập VGG19\n",
        "class VGG19(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.features = self._make_features()\n",
        "    self.classification_head = nn.Linear(in_features=25088, out_features=3)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.features(x)\n",
        "    out = out.view(out.size(0), -1)\n",
        "    out = self.classification_head(out)\n",
        "    return out\n",
        "\n",
        "  def _make_features(self):\n",
        "    config = [64, 64, 'MP', 128, 128, 'MP', 256, 256, 256, 256, 'MP', 512, 512, 512, 512, 'MP', 512, 512, 512, 512, 'MP']\n",
        "    layer = []\n",
        "    c_in = 3\n",
        "    for c in config:\n",
        "      if c == 'MP':\n",
        "        layer += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "      else:\n",
        "        layer += [nn.Conv2d(in_channels=c_in, out_channels=c, kernel_size=3, stride=1, padding=1), \n",
        "                  nn.BatchNorm2d(num_features=c), \n",
        "                  nn.ReLU6(inplace=True)]\n",
        "        c_in = c\n",
        "    return nn.Sequential(*layer)\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-t8F9oB2-Rr"
      },
      "source": [
        "def imshow(images, labels, predicted, target_names):\n",
        "  img = torchvision.utils.make_grid(images)\n",
        "  plt.imshow(img.permute(1, 2, 0).cpu().numpy())\n",
        "  [print(target_names[c], end=' ') for c in list(labels.cpu().numpy())]\n",
        "  print()\n",
        "  [print(target_names[c], end=' ') for c in list(predicted.cpu().numpy())]\n",
        "  print()\n",
        "  # print(target_names[list(labels.cpu().numpy())])\n",
        "  # print(target_names[list(predicted.cpu().numpy())])\n",
        "\n",
        "  # def imshow(img):\n",
        "  #   img = img / 2 + 0.5     # unnormalize\n",
        "  #   npimg = img.numpy()\n",
        "  #   plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "  #   plt.show()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hP7rl_OAD_9"
      },
      "source": [
        "# Hàm train với mỗi batch trong bộ dữ liệu\n",
        "def train_epoch(epoch, model, loader, loss_func, optimizer, device):\n",
        "  # Cho ảnh (đã được chia thành batch trong loader) lần lượt đi qua model, với mỗi ảnh và nhãn trong bộ dữ liệu là đầu vào của mạng.\n",
        "  model.train()             \n",
        "  running_loss = 0.0\n",
        "  reporting_steps = 60\n",
        "  for i, (images, labels) in enumerate(loader):\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    outputs = model(images)\n",
        "    # print('Type:', type(outputs), '\\nOutput shape:', outputs.size())      # Type: <class 'torch.Tensor'> Output shape: torch.Size([32, 3])\n",
        "    loss = loss_func(outputs, labels)\n",
        "\n",
        "    # Cập nhật tham số trước khi sang step khác\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    # Báo cáo sau reporting_step bước\n",
        "    if i % reporting_steps == reporting_steps-1:\n",
        "      print(f'Epoch {epoch} step {i} ave_loss {running_loss/reporting_steps:.4f}')\n",
        "      running_loss = 0.0\n",
        "\n",
        "# Hàm test \n",
        "def test_epoch(epoch, model, loader, device):\n",
        "  ytrue =[]\n",
        "  ypred = []\n",
        "  # Đặt model ở chế độ đánh giá (evaluate)\n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    \n",
        "    # Tính toán đầu ra cho từng ảnh, với nhãn dự đoán dựa trên số to nhất trong outputs\n",
        "    for i, (images, labels) in enumerate(loader):\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "      outputs = model(images)\n",
        "      _, predicted = torch.max(outputs, dim=1)\n",
        "      \n",
        "      ytrue += list(labels.cpu().numpy())\n",
        "      ypred += list(predicted.cpu().numpy())\n",
        "      \n",
        "  return ytrue, ypred   # Trả về nhãn thực, nhãn dự đoán của ảnh\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjtdL_WqqFLL",
        "outputId": "a7b1c426-b998-414a-f4f1-3e25d851631a"
      },
      "source": [
        "def main():\n",
        "  classes = get_classes()\n",
        "  datasets = prepare_data()\n",
        "\n",
        "  # img, label = datasets.train[0]\n",
        "  # print(classes[label], img.size)\n",
        "  # print('Number of images in train', len(datasets.train), 'Number of images in test', len(datasets.test))\n",
        "  # plt.imshow(img)\n",
        "  loaders = prepare_loader(datasets)\n",
        "  # images, labels = iter(loaders.train).next()\n",
        "  # print(images.shape, labels.shape)\n",
        "\n",
        "  device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "  model = VGG19().to(device)\n",
        "  # summary(model.cuda(), (3, 224, 224))\n",
        "  # images, labels = iter(loaders.train).next()\n",
        "  # # print(model)\n",
        "  # outputs = model(images)\n",
        "  # print(outputs.shape)\n",
        "  # print(outputs[0])\n",
        "  # _, predicted = torch.max(outputs, dim=1)\n",
        "  # print(predicted)\n",
        "  # imshow(images, labels, predicted, classes)\n",
        "\n",
        "  loss_func = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
        "  for epoch in range(10):\n",
        "    train_epoch(epoch, model, loaders.train, loss_func, optimizer, device)\n",
        "    ytrue, ypred = test_epoch(epoch, model, loaders.test, device)\n",
        "    print(classification_report(ytrue, ypred, target_names=classes))\n",
        "\n",
        "main()\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images in train: 6717 \n",
            "Number of images in test: 1607\n",
            "Index of classes: {'2C': 0, '3C': 1, '4C': 2}\n",
            "Type: <class 'torch.Tensor'> | size:  torch.Size([3, 224, 224])\n",
            "Number of batchs in train: 210 \n",
            "Number of batchs in test: 51\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 step 59 ave_loss 9.2767\n",
            "Epoch 0 step 119 ave_loss 2.5113\n",
            "Epoch 0 step 179 ave_loss 2.1114\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.54      0.32      0.40       409\n",
            "          3C       0.54      0.57      0.55       367\n",
            "          4C       0.75      0.87      0.80       831\n",
            "\n",
            "    accuracy                           0.66      1607\n",
            "   macro avg       0.61      0.59      0.59      1607\n",
            "weighted avg       0.64      0.66      0.64      1607\n",
            "\n",
            "Epoch 1 step 59 ave_loss 1.2977\n",
            "Epoch 1 step 119 ave_loss 0.9737\n",
            "Epoch 1 step 179 ave_loss 0.6869\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.40      0.75      0.52       409\n",
            "          3C       0.54      0.59      0.56       367\n",
            "          4C       0.83      0.45      0.58       831\n",
            "\n",
            "    accuracy                           0.56      1607\n",
            "   macro avg       0.59      0.59      0.56      1607\n",
            "weighted avg       0.66      0.56      0.56      1607\n",
            "\n",
            "Epoch 2 step 59 ave_loss 0.6116\n",
            "Epoch 2 step 119 ave_loss 0.5400\n",
            "Epoch 2 step 179 ave_loss 0.4457\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.49      0.89      0.64       409\n",
            "          3C       0.64      0.62      0.63       367\n",
            "          4C       0.93      0.57      0.71       831\n",
            "\n",
            "    accuracy                           0.67      1607\n",
            "   macro avg       0.69      0.70      0.66      1607\n",
            "weighted avg       0.75      0.67      0.67      1607\n",
            "\n",
            "Epoch 3 step 59 ave_loss 0.3736\n",
            "Epoch 3 step 119 ave_loss 0.2996\n",
            "Epoch 3 step 179 ave_loss 0.2762\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.48      0.81      0.60       409\n",
            "          3C       0.58      0.83      0.68       367\n",
            "          4C       0.94      0.44      0.60       831\n",
            "\n",
            "    accuracy                           0.62      1607\n",
            "   macro avg       0.67      0.69      0.63      1607\n",
            "weighted avg       0.74      0.62      0.62      1607\n",
            "\n",
            "Epoch 4 step 59 ave_loss 0.2131\n",
            "Epoch 4 step 119 ave_loss 0.1540\n",
            "Epoch 4 step 179 ave_loss 0.1341\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.44      0.90      0.59       409\n",
            "          3C       0.71      0.60      0.65       367\n",
            "          4C       0.98      0.55      0.70       831\n",
            "\n",
            "    accuracy                           0.65      1607\n",
            "   macro avg       0.71      0.68      0.65      1607\n",
            "weighted avg       0.78      0.65      0.66      1607\n",
            "\n",
            "Epoch 5 step 59 ave_loss 0.0941\n",
            "Epoch 5 step 119 ave_loss 0.0856\n",
            "Epoch 5 step 179 ave_loss 0.0680\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.52      0.81      0.64       409\n",
            "          3C       0.50      0.80      0.61       367\n",
            "          4C       0.98      0.46      0.62       831\n",
            "\n",
            "    accuracy                           0.63      1607\n",
            "   macro avg       0.67      0.69      0.63      1607\n",
            "weighted avg       0.76      0.63      0.62      1607\n",
            "\n",
            "Epoch 6 step 59 ave_loss 0.0629\n",
            "Epoch 6 step 119 ave_loss 0.0540\n",
            "Epoch 6 step 179 ave_loss 0.0445\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.60      0.85      0.71       409\n",
            "          3C       0.59      0.75      0.66       367\n",
            "          4C       0.99      0.67      0.80       831\n",
            "\n",
            "    accuracy                           0.73      1607\n",
            "   macro avg       0.73      0.76      0.72      1607\n",
            "weighted avg       0.80      0.73      0.74      1607\n",
            "\n",
            "Epoch 7 step 59 ave_loss 0.0408\n",
            "Epoch 7 step 119 ave_loss 0.0621\n",
            "Epoch 7 step 179 ave_loss 0.0524\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.64      0.82      0.72       409\n",
            "          3C       0.64      0.78      0.70       367\n",
            "          4C       0.98      0.75      0.85       831\n",
            "\n",
            "    accuracy                           0.77      1607\n",
            "   macro avg       0.75      0.78      0.76      1607\n",
            "weighted avg       0.82      0.77      0.78      1607\n",
            "\n",
            "Epoch 8 step 59 ave_loss 0.0220\n",
            "Epoch 8 step 119 ave_loss 0.0273\n",
            "Epoch 8 step 179 ave_loss 0.0436\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.63      0.88      0.74       409\n",
            "          3C       0.63      0.75      0.69       367\n",
            "          4C       1.00      0.73      0.84       831\n",
            "\n",
            "    accuracy                           0.77      1607\n",
            "   macro avg       0.76      0.79      0.75      1607\n",
            "weighted avg       0.82      0.77      0.78      1607\n",
            "\n",
            "Epoch 9 step 59 ave_loss 0.0238\n",
            "Epoch 9 step 119 ave_loss 0.0604\n",
            "Epoch 9 step 179 ave_loss 0.0202\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.57      0.78      0.66       409\n",
            "          3C       0.61      0.82      0.70       367\n",
            "          4C       0.97      0.65      0.78       831\n",
            "\n",
            "    accuracy                           0.72      1607\n",
            "   macro avg       0.72      0.75      0.71      1607\n",
            "weighted avg       0.79      0.72      0.73      1607\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xP3vQB1rELaL"
      },
      "source": [
        "#VGG19  ảnh 224: [56, 67, 62, 65, 63, 73, 77, 77, 72]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}